#!/bin/bash

# Multi-threaded Downloader
# A robust, configurable multi-threaded file downloader using curl
# Author: MT-Downloader Project
# License: MIT

set -euo pipefail

# Global variables
SCRIPT_NAME="$(basename "$0")"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
CONFIG_FILE="${PROJECT_ROOT}/config/mt-downloader.conf"
LOG_DIR="${PROJECT_ROOT}/logs"
LOG_FILE="${LOG_DIR}/mt-downloader.log"

# Default configuration
DEFAULT_THREADS=4
DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=3
DEFAULT_OUTPUT_DIR="./downloads"
DEFAULT_USER_AGENT="MT-Downloader/1.0"
DEFAULT_MAX_SPEED=""
DEFAULT_MIN_SPEED=""

# Runtime variables
THREADS=$DEFAULT_THREADS
TIMEOUT=$DEFAULT_TIMEOUT
RETRIES=$DEFAULT_RETRIES
OUTPUT_DIR=$DEFAULT_OUTPUT_DIR
USER_AGENT=$DEFAULT_USER_AGENT
MAX_SPEED=$DEFAULT_MAX_SPEED
MIN_SPEED=$DEFAULT_MIN_SPEED
VERBOSE=false
QUIET=false
RESUME=false
URL_FILE=""
URLS=()

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # Ensure log directory exists
    mkdir -p "$LOG_DIR"
    
    # Write to log file
    echo "[$timestamp] [$level] $message" >> "$LOG_FILE"
    
    # Output to console based on verbosity
    if [[ "$level" == "ERROR" ]]; then
        echo -e "${RED}[ERROR]${NC} $message" >&2
    elif [[ "$level" == "WARN" ]]; then
        echo -e "${YELLOW}[WARN]${NC} $message" >&2
    elif [[ "$level" == "INFO" && "$QUIET" == "false" ]]; then
        echo -e "${GREEN}[INFO]${NC} $message"
    elif [[ "$level" == "DEBUG" && "$VERBOSE" == "true" ]]; then
        echo -e "${BLUE}[DEBUG]${NC} $message"
    fi
}

# Load configuration file
load_config() {
    if [[ -f "$CONFIG_FILE" ]]; then
        log "DEBUG" "Loading configuration from $CONFIG_FILE"
        # Source the config file safely
        while IFS='=' read -r key value; do
            # Skip comments and empty lines
            [[ $key =~ ^[[:space:]]*# ]] && continue
            [[ -z "$key" ]] && continue
            
            # Remove quotes and whitespace
            key=$(echo "$key" | tr -d '[:space:]')
            value=$(echo "$value" | sed 's/^["'\'']*//;s/["'\'']*$//')
            
            case "$key" in
                THREADS) THREADS="$value" ;;
                TIMEOUT) TIMEOUT="$value" ;;
                RETRIES) RETRIES="$value" ;;
                OUTPUT_DIR) OUTPUT_DIR="$value" ;;
                USER_AGENT) USER_AGENT="$value" ;;
                MAX_SPEED) MAX_SPEED="$value" ;;
                MIN_SPEED) MIN_SPEED="$value" ;;
            esac
        done < "$CONFIG_FILE"
    else
        log "DEBUG" "Configuration file not found, using defaults"
    fi
}

# Display help
show_help() {
    cat << EOF
$SCRIPT_NAME - Multi-threaded File Downloader

USAGE:
    $SCRIPT_NAME [OPTIONS] [URLs...]
    $SCRIPT_NAME [OPTIONS] -f URL_FILE

DESCRIPTION:
    A robust multi-threaded downloader that can download multiple files
    concurrently with retry logic, resume capability, and comprehensive logging.

OPTIONS:
    -h, --help              Show this help message
    -t, --threads N         Number of concurrent downloads (default: $DEFAULT_THREADS)
    -o, --output DIR        Output directory (default: $DEFAULT_OUTPUT_DIR)
    -f, --file FILE         Read URLs from file (one URL per line)
    -r, --retries N         Number of retry attempts (default: $DEFAULT_RETRIES)
    -T, --timeout N         Timeout in seconds (default: $DEFAULT_TIMEOUT)
    -u, --user-agent UA     User agent string (default: $DEFAULT_USER_AGENT)
    -s, --max-speed SPEED   Maximum download speed (e.g., 1M, 500K)
    -m, --min-speed SPEED   Minimum download speed (e.g., 100K)
    -R, --resume            Resume partial downloads
    -v, --verbose           Enable verbose output
    -q, --quiet             Suppress non-error output
    -c, --config FILE       Use custom configuration file

EXAMPLES:
    # Download single file
    $SCRIPT_NAME https://example.com/file.zip

    # Download multiple files with 8 threads
    $SCRIPT_NAME -t 8 https://example.com/file1.zip https://example.com/file2.zip

    # Download from URL list file
    $SCRIPT_NAME -f urls.txt -o /tmp/downloads

    # Resume downloads with speed limit
    $SCRIPT_NAME -R -s 1M -f urls.txt

    # Verbose mode with custom output directory
    $SCRIPT_NAME -v -o ~/Downloads https://example.com/large-file.iso

CONFIGURATION:
    Configuration can be set via $CONFIG_FILE
    Command line options override configuration file settings.

LOGS:
    Logs are written to: $LOG_FILE
    Use 'tail -f $LOG_FILE' to monitor in real-time.

EOF
}

# Validate URL format
validate_url() {
    local url="$1"
    if [[ ! "$url" =~ ^https?:// ]]; then
        log "ERROR" "Invalid URL format: $url"
        return 1
    fi
    return 0
}

# Get filename from URL
get_filename() {
    local url="$1"
    local filename
    
    # Try to get filename from Content-Disposition header
    filename=$(curl -sI "$url" | grep -i 'content-disposition' | sed -n 's/.*filename="\?\([^"]*\)"\?.*/\1/p' | tr -d '\r')
    
    # If not found, extract from URL
    if [[ -z "$filename" ]]; then
        filename=$(basename "$url" | cut -d'?' -f1)
    fi
    
    # If still empty, generate a default name
    if [[ -z "$filename" ]]; then
        filename="download_$(date +%s)"
    fi
    
    echo "$filename"
}

# Download single file
download_file() {
    local url="$1"
    local output_file="$2"
    local attempt=1
    
    log "INFO" "Starting download: $(basename "$output_file")"
    log "DEBUG" "URL: $url"
    log "DEBUG" "Output: $output_file"
    
    while [[ $attempt -le $RETRIES ]]; do
        log "DEBUG" "Download attempt $attempt/$RETRIES for $(basename "$output_file")"
        
        # Build curl command
        local curl_cmd=(
            curl
            --location
            --user-agent "$USER_AGENT"
            --connect-timeout "$TIMEOUT"
            --max-time $((TIMEOUT * 10))
            --fail
            --show-error
            --progress-bar
        )
        
        # Add resume option
        if [[ "$RESUME" == "true" && -f "$output_file" ]]; then
            curl_cmd+=(--continue-at -)
        fi
        
        # Add speed limits
        if [[ -n "$MAX_SPEED" ]]; then
            curl_cmd+=(--limit-rate "$MAX_SPEED")
        fi
        
        if [[ -n "$MIN_SPEED" ]]; then
            curl_cmd+=(--speed-limit "$MIN_SPEED")
        fi
        
        # Add output and URL
        curl_cmd+=(--output "$output_file" "$url")
        
        # Execute download
        if "${curl_cmd[@]}" 2>&1; then
            log "INFO" "✓ Download completed: $(basename "$output_file")"
            return 0
        else
            local exit_code=$?
            log "WARN" "Download attempt $attempt failed for $(basename "$output_file") (exit code: $exit_code)"
            
            if [[ $attempt -lt $RETRIES ]]; then
                local wait_time=$((attempt * 2))
                log "DEBUG" "Waiting ${wait_time}s before retry..."
                sleep $wait_time
            fi
        fi
        
        ((attempt++))
    done
    
    log "ERROR" "✗ Download failed after $RETRIES attempts: $(basename "$output_file")"
    return 1
}

# Process downloads in parallel
process_downloads() {
    local -a pids=()
    local -a files=()
    local active_downloads=0
    local completed=0
    local failed=0
    local total=${#URLS[@]}
    
    log "INFO" "Starting $total downloads with $THREADS threads"
    
    # Create output directory
    mkdir -p "$OUTPUT_DIR"
    
    for url in "${URLS[@]}"; do
        # Wait if we've reached the thread limit
        while [[ $active_downloads -ge $THREADS ]]; do
            # Check for completed downloads
            for i in "${!pids[@]}"; do
                if ! kill -0 "${pids[$i]}" 2>/dev/null; then
                    wait "${pids[$i]}"
                    local exit_code=$?
                    
                    if [[ $exit_code -eq 0 ]]; then
                        ((completed++))
                        log "INFO" "Progress: $completed/$total completed"
                    else
                        ((failed++))
                        log "WARN" "Progress: $completed/$total completed, $failed failed"
                    fi
                    
                    # Remove completed PID
                    unset pids[$i]
                    unset files[$i]
                    ((active_downloads--))
                    break
                fi
            done
            
            # Brief pause to prevent busy waiting
            sleep 0.1
        done
        
        # Start new download
        local filename
        filename=$(get_filename "$url")
        local output_file="$OUTPUT_DIR/$filename"
        
        # Check if file exists and we're not resuming
        if [[ -f "$output_file" && "$RESUME" != "true" ]]; then
            log "WARN" "File exists, skipping: $filename"
            continue
        fi
        
        # Start download in background
        download_file "$url" "$output_file" &
        local pid=$!
        
        pids+=("$pid")
        files+=("$filename")
        ((active_downloads++))
        
        log "DEBUG" "Started download thread (PID: $pid) for $filename"
    done
    
    # Wait for all remaining downloads
    log "INFO" "Waiting for remaining downloads to complete..."
    for pid in "${pids[@]}"; do
        if kill -0 "$pid" 2>/dev/null; then
            wait "$pid"
            local exit_code=$?
            
            if [[ $exit_code -eq 0 ]]; then
                ((completed++))
            else
                ((failed++))
            fi
        fi
    done
    
    # Final report
    log "INFO" "Download summary: $completed completed, $failed failed, $total total"
    
    if [[ $failed -gt 0 ]]; then
        return 1
    fi
    
    return 0
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -t|--threads)
                THREADS="$2"
                shift 2
                ;;
            -o|--output)
                OUTPUT_DIR="$2"
                shift 2
                ;;
            -f|--file)
                URL_FILE="$2"
                shift 2
                ;;
            -r|--retries)
                RETRIES="$2"
                shift 2
                ;;
            -T|--timeout)
                TIMEOUT="$2"
                shift 2
                ;;
            -u|--user-agent)
                USER_AGENT="$2"
                shift 2
                ;;
            -s|--max-speed)
                MAX_SPEED="$2"
                shift 2
                ;;
            -m|--min-speed)
                MIN_SPEED="$2"
                shift 2
                ;;
            -R|--resume)
                RESUME=true
                shift
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -q|--quiet)
                QUIET=true
                shift
                ;;
            -c|--config)
                CONFIG_FILE="$2"
                shift 2
                ;;
            -*)
                log "ERROR" "Unknown option: $1"
                echo "Use '$SCRIPT_NAME --help' for usage information."
                exit 1
                ;;
            *)
                URLS+=("$1")
                shift
                ;;
        esac
    done
}

# Load URLs from file
load_urls_from_file() {
    if [[ -n "$URL_FILE" ]]; then
        if [[ ! -f "$URL_FILE" ]]; then
            log "ERROR" "URL file not found: $URL_FILE"
            exit 1
        fi
        
        log "DEBUG" "Loading URLs from file: $URL_FILE"
        
        while IFS= read -r line; do
            # Skip empty lines and comments
            [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]] && continue
            
            # Trim whitespace
            line=$(echo "$line" | xargs)
            
            if validate_url "$line"; then
                URLS+=("$line")
            fi
        done < "$URL_FILE"
        
        log "INFO" "Loaded ${#URLS[@]} URLs from file"
    fi
}

# Validate configuration
validate_config() {
    # Validate numeric values
    if ! [[ "$THREADS" =~ ^[0-9]+$ ]] || [[ "$THREADS" -lt 1 ]] || [[ "$THREADS" -gt 50 ]]; then
        log "ERROR" "Invalid thread count: $THREADS (must be 1-50)"
        exit 1
    fi
    
    if ! [[ "$RETRIES" =~ ^[0-9]+$ ]] || [[ "$RETRIES" -lt 0 ]] || [[ "$RETRIES" -gt 10 ]]; then
        log "ERROR" "Invalid retry count: $RETRIES (must be 0-10)"
        exit 1
    fi
    
    if ! [[ "$TIMEOUT" =~ ^[0-9]+$ ]] || [[ "$TIMEOUT" -lt 1 ]] || [[ "$TIMEOUT" -gt 300 ]]; then
        log "ERROR" "Invalid timeout: $TIMEOUT (must be 1-300 seconds)"
        exit 1
    fi
    
    # Check if curl is available
    if ! command -v curl &> /dev/null; then
        log "ERROR" "curl is required but not installed"
        exit 1
    fi
    
    # Validate output directory
    if [[ ! -d "$OUTPUT_DIR" ]]; then
        if ! mkdir -p "$OUTPUT_DIR" 2>/dev/null; then
            log "ERROR" "Cannot create output directory: $OUTPUT_DIR"
            exit 1
        fi
    fi
    
    if [[ ! -w "$OUTPUT_DIR" ]]; then
        log "ERROR" "Output directory is not writable: $OUTPUT_DIR"
        exit 1
    fi
}

# Main function
main() {
    log "INFO" "MT-Downloader starting (PID: $$)"
    
    # Load configuration
    load_config
    
    # Parse command line arguments
    parse_args "$@"
    
    # Load URLs from file if specified
    load_urls_from_file
    
    # Validate we have URLs to download
    if [[ ${#URLS[@]} -eq 0 ]]; then
        log "ERROR" "No URLs provided"
        echo "Use '$SCRIPT_NAME --help' for usage information."
        exit 1
    fi
    
    # Validate all URLs
    for url in "${URLS[@]}"; do
        if ! validate_url "$url"; then
            exit 1
        fi
    done
    
    # Validate configuration
    validate_config
    
    # Log configuration
    log "INFO" "Configuration: threads=$THREADS, retries=$RETRIES, timeout=${TIMEOUT}s, output=$OUTPUT_DIR"
    log "DEBUG" "User-Agent: $USER_AGENT"
    [[ -n "$MAX_SPEED" ]] && log "DEBUG" "Max speed: $MAX_SPEED"
    [[ -n "$MIN_SPEED" ]] && log "DEBUG" "Min speed: $MIN_SPEED"
    [[ "$RESUME" == "true" ]] && log "DEBUG" "Resume enabled"
    
    # Start downloads
    if process_downloads; then
        log "INFO" "All downloads completed successfully"
        exit 0
    else
        log "ERROR" "Some downloads failed"
        exit 1
    fi
}

# Handle signals
trap 'log "WARN" "Received interrupt signal, terminating..."; kill 0; exit 130' INT TERM

# Run main function
main "$@"